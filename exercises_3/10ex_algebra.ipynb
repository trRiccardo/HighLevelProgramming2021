{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator, FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_ticks(ax, xMaj, xMin, yMaj, yMin):\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(xMaj))\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator(xMin))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(yMaj))\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator(yMin))\n",
    "    ax.tick_params(which='major', width=1.0, length=10, direction=\"in\", labelsize=12)\n",
    "    ax.tick_params(which='minor', width=1.0, length=5, direction=\"in\", labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. PCA on 3D dataset\n",
    "\n",
    "* Generate a dataset simulating 3 features, each with N entries (N being ${\\cal O}(1000)$). Each feature is made by random numbers generated according the normal distribution $N(\\mu,\\sigma)$ with mean $\\mu_i$ and standard deviation $\\sigma_i$, with $i=1, 2, 3$. Generate the 3 variables $x_{i}$ such that:\n",
    "    * $x_1$ is distributed as $N(0,1)$\n",
    "    * $x_2$ is distributed as $x_1+N(0,3)$\n",
    "    * $x_3$ is given by $2x_1+x_2$\n",
    "* Find the eigenvectors and eigenvalues using the eigendecomposition of the covariance matrix\n",
    "* Find the eigenvectors and eigenvalues using the SVD. Check that the two procedures yield to same result\n",
    "* What percent of the total dataset's variability is explained by the principal components? Given how the dataset was constructed, do these make sense? Reduce the dimensionality of the system so that at least 99% of the total variability is retained\n",
    "* Redefine the data according to the new basis from the PCA\n",
    "* Plot the data, in both the original and the new basis. The figure should have 2 rows (the original and the new basis) and 3 columns (the $[x_0, x_1]$, $[x_0, x_2]$ and $[x_1, x_2]$ projections) of scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The covariance matrix is:\n",
      " [[ 1.03580401  1.13947062  3.21107863]\n",
      " [ 1.13947062  9.82037416 12.0993154 ]\n",
      " [ 3.21107863 12.0993154  18.52147267]]\n",
      "\n",
      "EIGENDECOMPOSITION:\n",
      "-Eigenvalues:\n",
      " [ 2.74371608e+01+0.j  1.94049006e+00+0.j -3.73673330e-16+0.j] -> [ 2.74371608e+01  1.94049006e+00 -3.73673330e-16]\n",
      "-Eigenvectors:\n",
      " [[-0.12351467  0.56398356 -0.81649658]\n",
      " [-0.56722131 -0.71525752 -0.40824829]\n",
      " [-0.81425065  0.4127096   0.40824829]]\n",
      "\n",
      "EIGENDECOMPOSITION USING SVD:\n",
      "-Eigenvalues:\n",
      " [2.74439175e+01 1.94348595e+00 2.49533708e-30]\n",
      "-Eigenvectors:\n",
      " [[-0.12361418  0.56396176 -0.81649658]\n",
      " [-0.56709509 -0.7153576  -0.40824829]\n",
      " [-0.81432346  0.41256593  0.40824829]] \n",
      "\n",
      "The two procedures approximately yield the same eigenvalues.\n",
      "The two procedures approximately yield the same eigenvectors.\n"
     ]
    }
   ],
   "source": [
    "# generate dataset\n",
    "N = 1000\n",
    "x1 = np.random.normal(0, 1, N)\n",
    "x2 = np.random.normal(0, 3, N) + x1\n",
    "x3 = 2 * x1 + x2\n",
    "data = np.array([x1, x2, x3])\n",
    "\n",
    "# get covariance\n",
    "cov = np.cov(data)\n",
    "print(\"The covariance matrix is:\\n\", cov)\n",
    "\n",
    "'''\n",
    "    Eigendecomposition.\n",
    "'''\n",
    "\n",
    "# get eigenvalues and eigenvectors\n",
    "egl, egv = la.eig(cov)\n",
    "\n",
    "# sort them in order to match the latter SVD \n",
    "index = np.argsort(egl)[::-1]\n",
    "egl = egl[index]\n",
    "egv = egv[:, index]\n",
    "egl_real = np.real_if_close(egl)\n",
    "print(\"\\nEIGENDECOMPOSITION:\")\n",
    "print(\"-Eigenvalues:\\n\", egl, \"->\", egl_real)\n",
    "print(\"-Eigenvectors:\\n\", egv)\n",
    "\n",
    "'''\n",
    "    Perform the eigendecomposition using the SVD.\n",
    "    The third eigenvalue is sensibly different. If one uses\n",
    "    the np.allclose() method with a high precision of the \n",
    "    orderd o(1.e-20), the eingevalues are in fact different.\n",
    "'''\n",
    "\n",
    "# perform the Single Value Decomposition\n",
    "U, S, V = la.svd(data)\n",
    "egl_svd = S**2 / (N - 1)\n",
    "egv_svd = U\n",
    "print(\"\\nEIGENDECOMPOSITION USING SVD:\")\n",
    "print(\"-Eigenvalues:\\n\", egl_svd)\n",
    "print(\"-Eigenvectors:\\n\", egv_svd, \"\\n\")\n",
    "\n",
    "#check = np.allclose(egl, egl_svd, 1.e-20)\n",
    "check = np.allclose(egl, egl_svd, 1.e-2)\n",
    "if check:\n",
    "    print(\"The two procedures approximately yield the same eigenvalues.\")\n",
    "check_egv = np.allclose(egv, egv_svd, 1.e-2)\n",
    "if check_egv:\n",
    "    print(\"The two procedures approximately yield the same eigenvectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By selecting the component 0 we retain 93.39467 of the total variability.\n",
      "By selecting the component 1 we retain 6.60533 of the total variability.\n",
      "By selecting the component 2 we retain 0.00000 of the total variability.\n",
      "By selecting the component (0, 1) we retain 100.00000 of the total variability.\n",
      "By selecting the component (0, 2) we retain 93.39467 of the total variability.\n",
      "By selecting the component (1, 2) we retain 93.39467 of the total variability.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Principal Component Analysis (PCA) via dimension\n",
    "    reduction. We begin with p = 3 features, hence the\n",
    "    dimensionality\n",
    "'''\n",
    "\n",
    "# get lambda matrix\n",
    "Lambda = np.diag(egl_real)\n",
    "\n",
    "# select components\n",
    "components = (0, 1, 2, (0, 1), (0, 2), (1, 2))\n",
    "\n",
    "# compute variability for each component\n",
    "variability = (abs(Lambda[0,0])/Lambda.trace(), abs(Lambda[1,1])/Lambda.trace(),\n",
    "               abs(Lambda[2,2])/Lambda.trace(), abs(Lambda[0,0]+Lambda[1,1])/Lambda.trace(),\n",
    "               abs(Lambda[0,0]+Lambda[2,2])/Lambda.trace(), abs(Lambda[0,0]+Lambda[2,2])/Lambda.trace())\n",
    "\n",
    "for i, j in zip(components, variability):\n",
    "    print(\"By selecting the component\", i, \"we retain %.5f of the total variability.\" % (j * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. PCA on a nD dataset\n",
    "\n",
    "* Start from the dataset you have genereted in the previous exercise and add uncorrelated random noise. Such noise should be represented by other 10 uncorrelated variables normally distributed, with a standard deviation much smaller (e.g. a factor 20) than those used to generate the $x_1$ and $x_2$. Repeat the PCA procedure and compare the results with what you have obtained before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **Optional**: PCA on the MAGIC dataset\n",
    "\n",
    "Perform a PCA on the magic04.data dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset and its description on the proper data directory\n",
    "#!wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data -P data/\n",
    "#!wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.names -P data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
